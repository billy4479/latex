\documentclass[12pt]{extarticle}

\setlength{\headheight}{16pt} % ??? we do what fancyhdr tells us to do  

\title{Advanced Programming and Optimization}
\author{Giacomo Ellero}
\date{a.y. 2024/2025}

\usepackage{preamble}
\usepackage{preamble_svg}
%\usepackage{preamble_code}

\renewcommand{\vec}[1]{\bm{#1}}

\begin{document}

\oldfirstpage

\section{Introduction}

This course will all be about
\begin{align}
	\max f(x), & \text{subject to}                          \\
	g_i(x)     & \leq b_i \quad \text{for } i = 1, \dots, m \\
	x          & \in \R^n
\end{align}
where $f, g_1, \dots, g_m: \R^n \to \R$ are linear functions and $b_1, \dots, b_m \in \R$.
This is the standard \emph{linear programming} problem and can be solved in polynomial time.

However we are also going to be looking at problems where $x \in \Z^n$ (integers).
This is a NP hard problem.

The last part of the course we will have the case where $f, g_1, \dots, g_m$ are not linear
but they are \emph{convex} instead. This also is a hard problem.

\section{Linear programming}

Recall that even though we have stated the problem with less-than-or-equal, we can just multiply
the constraints by $-1$ to flip the inequality if needed.
Similarly we can multiply $f$ by $-1$ to change $\min$ to $\max$ or viceversa.

In linear programming our constraint make a polygon in an $n$-dimensional space.
If we let $\vec a$ be the vector of the coefficients of $f$ the problem reduces to finding the
point which is further away from the origin perpendicular to $\vec a$.

It is not always possible to find an unique solution to a linear programming problem: sometimes
the problem has multiple solutions, it is undecidable, or unbounded.

\subsubsection{Examples}

\begin{example}{Flow}{}
	Recall that the flow problem we saw in CS2 can be written as a linear programming problem:
	each edge has a constraint of $-c_i \leq e_i \leq c_i$ (where $c_i$ is the capacity of each edge)
	and each node has an additional constraint of flow preservation.
	We can maximize the output from the source or the input to the destination.
\end{example}

\begin{example}{Icecream production}{}
	Each month $i$ has a certain icecream demand $d_i$.
	Changing the production of icecream has a cost $a_1$ and the cost of storing icecream we pay $a_2$.
	What is the optimal amount of icecream to be produced?
\end{example}

\begin{proof}[Solution]
	For each month $i$ we want
	\begin{equation}
		x_i + s_{i-1} - s_i = d_i
	\end{equation}
	where $x_i$ is the production of icecream and $s_i$ is the amount we have in storage.

	Our objective will be
	\begin{equation}
		\min a_1 \sum \abs{x_i - x_{i-1}} + a_2 \sum s_i
	\end{equation}
	but this is not a linear function!

	Instead we introduce two new variables $y_i$ which represents the increase in the production
	and $z_i$ which represents the decrease in the production.
	We can now add the constraint
	\begin{align}
		x_i - {x_{i-1}} & = y_i - z_i \\
		y_i             & \geq 0      \\
		z_i             & \geq 0
	\end{align}
	and our objective becomes
	\begin{equation}
		\min a_1 \sum y_i + a_1 \sum z_i + a_2 \sum s_i
	\end{equation}
	which is indeed linear.
	Moreover, we notice that an optimal solution either has $y_i = 0$ or $z_i = 0$,
	hence the problem is equivalent to the first one.
\end{proof}

\subsection{0-sum games}

A 0-sum game has the following properties:
\begin{itemize}
	\item There is a finite set of strategies
	\item Assume player $A$ plays move $i$ and player $B$ plays $j$,
	      then the game pays $m_{ij}$ to player $A$ and $-m_{ij}$ to player $B$.
\end{itemize}
Therefore we can consider the game to be a matrix $M$.

\subsubsection{Example: Colonel Blotto}

\paragraph{Modelling the game}
There are two armies ($B$ and $E$) which are fighting at $3$ mountain passes ($a, b, c$).
$B$ and $E$ have $5$ regiments each.

What each player has to decide is how to partition the regiments:
we will have $k, \ell, m$ such that $k \leq \ell \leq m$ and $k+\ell + m = 5$;
then each group $k, \ell, m$ will be randomly assigned to a mountain pass.

The player who has more regiments in a certain pass will win the pass,
in particular if the number of regiments is the same we will have a draw.
The player who wins more passes wins the game.

We will model the payoff as the probability of winning minus the probability of losing.

\paragraph{Example game 1}
Assume that $B$ plays $i = (0,0,5)$ and $E$ plays $j = (5, 0, 0)$.
Then we have that
\begin{equation}
	m_{ij} = \frac{1}{3} \cdot 0 + \frac{2}{3} \cdot 0 = 0
\end{equation}
where the first probability represents the case where the two armies meet, therefore we have a draw;
the second probability is for all other cases, where one army wins and the other one loses,
therefore we again get a draw.

\paragraph{Example game 2}
Assume that $B$ plays $i = (0,1,4)$ and $E$ plays $j = (5, 0, 0)$.
Then we have that
\begin{equation}
	m_{ij} = \frac{1}{3} \cdot 1 + \frac{2}{3} \cdot 0 = \frac{1}{3}
\end{equation}
similarly to the case above.

\paragraph{How to choose the best strategy}
In this way we can construct a matrix with all the payoffs, however how can we choose the best one?
We could assume that the opponent chooses a strategy at random, therefore we should choose the
strategy with the highest expected payoff, but the enemy is also a skilled player, therefore he
won't choose a strategy at random.

Players will choose based on the worst possible outcome, but then the worst case scenario will
always realize.
Moreover, even if each player knew that the other one is playing the \say{optimal} strategy,
the best option would still be to play the same strategy.
This is called \emph{pure Nash equilibrium}.

\begin{definition}{Pure Nash equilibrium}{pure-nash-eq}
	There exists a pair of pure strategies $(i, j)$ which are the best responses to each other.
\end{definition}

\subsubsection{Rock-Paper-Scissors}

\paragraph{Normal game}
This game does not have a Nash equilibrium, however we can have a mixed strategy.

\begin{definition}{Mixed Nash equilibrium}{mixed-nash-eq}
	$(\tilde x, \tilde y)$ is a mixed Nash equilibrium if each player's response $\alpha(\tilde y)$
	and $\beta(\tilde x)$ is such that
	\begin{equation}
		\beta(\tilde x) = x^T M y = \alpha(\tilde y)
	\end{equation}
\end{definition}

The payoff $(x, y)$ will be
\begin{equation}
	\sum_{i, j} m_{ij} \cdot P(A \text{ plays } i, B \text{ plays } j)
	= \sum_{i, j} m_{ij} x_i y_i = x^T M y
\end{equation}

Therefore in this case, the mixed Nash equilibrium is to choose a strategy uniformly at random:
even if the opponent knew my strategy, there is no better way to respond.

\paragraph{Easter Bunny and Santa Claus}
Assume now that Santa Claus and the Easter Bunny play a game of R-P-S,
however BS doesn't know how to use scissors.

Assume SC chooses strategy $x$, we claim then for each mixed strategy $y$ of the EB,
there exists a pure strategy $y'$ with at least the same payoff.

Indeed EB can achieve
\begin{equation}
	\min \{ \underbrace{x_p - x_s}_{\text{EB plays rock}},
	\underbrace{ -x_r + x_s}_{\text{EB plays paper}}\} = \beta(x)
\end{equation}
Meanwhile SC will max the worst case scenario:
\begin{equation}
	x_0 = \max_{x} \min \{ \underbrace{x_p - x_s}_{\text{EB plays rock}} ,
	\underbrace{ -x_r + x_s}_{\text{EB plays paper}}\}
	= \max_x \beta(x)
	= \max_x \min_y x^T M y
\end{equation}

Therefore SC strategy can be solved through a linear program:
\begin{align}
	\max             x_0 & \quad \text{subject to}                    \\
	x_0                  & \leq x_p - x_s          \label{eq:bunny-r} \\
	x_0                  & \leq -x_r + x_s         \label{eq:bunny-p} \\
	x_p + x_r + x_s      & = 1                                        \\
	x_p, x_r, x_s        & \geq 0
\end{align}
where \cref{eq:bunny-r} is what happens when EB plays rock, \cref{eq:bunny-p} is when EB plays paper
and the other two constraints are there to make sure that $x$ is a valid mixed strategy.
Putting this program into a solver we get that the optimal solution is $\tilde x = (0, 2/3, 1/3)$
and pays $1/3$.

Similarly, for the EB we can write another linear program.
\begin{equation}
	y_0 = \min_{y} \max \{ \underbrace{y_p}_{\text{SC plays rock}} ,
	\underbrace{y_r},
	\underbrace{ -y_r + y_p}_{\text{EB plays paper}}\}
	= \min_x \alpha(x)
	= \min_x \max_y x^T M y
\end{equation}
Hence
\begin{align}
	\min y_0  & \quad \text{subject to} \\
	y_0       & \leq y_p                \\
	y_0       & \leq y_r                \\
	y_0       & \leq -y_r + y_p         \\
	y_p + y_r & = 1                     \\
	y_p, y_r  & \geq 0
\end{align}
and solving the program gives that the optimal solution is $\tilde y = (1/3, 2/3)$ which pays $1/3$
(therefore EB loses).
Note that this is the same win that SC gets.
We have
\begin{equation}
	\tilde x_0 = \beta(\tilde x) \leq \tilde x^T M \tilde y \leq \alpha(\tilde y) = \tilde y_0
\end{equation}
therefore $(\tilde x, \tilde y)$ is a mixed Nash equilibrium.

\begin{theorem}{Von Neumann}{vn}
	In a finite zero-sum game $x_0 = y_0$.
	Therefore it does not matter who chooses the strategy first.
\end{theorem}


\subsubsection{AA}

We want to find a line $y = ax + b$ which separates two kind of points $p$ and $q$
such that $p$ are above the line and $q$ are below.
We try to write this as a linear problem
\begin{align}
	y(p_i) > ax(p_i) + b \quad \forall i = 1, \dots, m \\
	y(q_i) < ax(q_i) + b \quad \forall i = 1, \dots, m
\end{align}

However, this is not a linear program, because the inequality are strict.
We can fix this by introducing another variable $\delta$ and a constraint $\delta \geq 0$,
moreover we also need to $\max$ is, since, ideally we'd like for $\delta$ to be $> 0$ but, again,
we are not allowed to have strict inequalities.
\begin{align}
	\max \delta & \text{ subject to}                                   \\
	y(p_i)      & > ax(p_i) + b + \delta \quad \forall i = 1, \dots, m \\
	y(q_i)      & < ax(q_i) + b + \delta \quad \forall i = 1, \dots, m \\
	\delta      & \geq 0
\end{align}

\subsection{Affine and convex geometry}
\subsubsection{Affinity}

Let $L$ be a linear subspace of $\R^d$.
Then $A = a + L$ with $a \in \R$ is a shifted linear subspace: we call it an \emph{affine space}.

Firstly we note that $A = a + L = x + L$ $\forall x \in A$: indeed if $x \in A$ then $x-a \in L$,
then for $y \in a + L$ we have that $y - a - (x - a) \in L$ giving $y \in x + L$.

We also define the \emph{affine hull} of $X \subseteq \R^d$ to be the intersection of all affine
subspaces containing $X$.

\begin{proposition}{}{}
	The affine hull of $X \subseteq \R^d$ can be written as
	\begin{equation}
		\mathrm{aff. hull}(X) =
		\left\{ \sum \alpha_i x_i \left| \substack{x_i \in X \\ \sum \alpha_i = 1} \right. \right \}
	\end{equation}
\end{proposition}
\begin{proof}
	First we prove that the set of affine combinations is included in the affine hull.
	By definition of affine hull we have $X \subseteq A = x_1 + L$.
	Moreover
	\begin{equation}
		\sum x_i \alpha_i = x_1 + \left(\sum \alpha_i (x_i - x_1)\right) \in x_1 + L = A
	\end{equation}

	Then we prove that affine hull is included in the set of affine combinations.
\end{proof}

Now we consider the dimensions of these spaces:
\begin{itemize}
	\item $\dim(L) =$ max number of linear independent vectors in $L$.
	\item $\dim(A) = \dim(L)$.
	\item $\dim(X) = \dim(\mathrm{aff. hull}(X))$.
	\item $\dim(\varnothing) = -1$
\end{itemize}
take these as definitions.

In particular a point is an affine space with dimension 0, a line has dimension 1,
a plane has dimension 2, and an hyperplane in $\R^d$ has dimension $d-1$.
Moreover, note that hyperplanes can be written as
\begin{equation}
	\{ x: \R^d \mid a^T x = b \}
\end{equation}

Observe that affine spaces spaces $A$ of dimensions $k \leq d-1$ are intersections of hyperplanes
(proof in lecture notes).

We call \emph{halfspace} the set
\begin{equation}
	\{x \in \R ^d : a^T x \leq b \}
\end{equation}

\subsubsection{Convexity}

We define the convex hull of a set $X$ as the intersection of all convex sets containing $X$.
Moreover we define a convex combination as $\sum \alpha_i x_i$ such that $x_i \in X$ and
$\sum \alpha_i = 1$.

The convex hull of $X$, i.e. $\mathrm{conv}(X)$ has the following properties:
\begin{itemize}
	\item $\mathrm{conv}(X)$ is convex itself
	\item $\mathrm{conv}(X)$ is the set of convex combinations of elements of $X$, that is
	      \begin{equation}
		      \mathrm{conv}(X) =
		      \left\{ \left.\sum_{i = 1}^k \alpha_i x_i \,\right|\, k \in \N^+ , x_i \in X, \sum_{i = 1}^k \alpha_i = 1 \right\}
	      \end{equation}
	\item $\mathrm{conv}(X) \subseteq X$
	\item For $X$ finite $\mathrm{conv}(X)$ is compact (closed and bounded)
\end{itemize}

\begin{theorem}{Caratheodory}{caratheodory}
	Let $X \subseteq \R^n$ and $d = \dim X$.
	Then
	\begin{equation}
		\mathrm{conv}(X) =
		\left\{ \left.\sum_{i = 1}^{d+1} \alpha_i x_i \,\right|\, x_i \in X, \sum_{i = 1}^k \alpha_i = 1 \right\}
	\end{equation}
\end{theorem}

\begin{proof}
	We know that there exists $k \in \N^+$ such that the theorem is true, let $k$ be the smallest one.
	If $k \leq d + 1$ we are done as we can set the remaining coefficients to $0$.

	We will show by contradiction that it is not possible that $k > d + 1$.
	Let $\{x_1, \dots, x_k\} = X'$: they are affine dependant;
	then there exists $\beta \neq 0 \in \R^k$ s.t. $\sum \beta_i x_i = 0$ and $\sum \beta_i = 0$.

	We know that for any $x \in X$ we can find $\alpha_i$ such that $x = \sum^k_{i = 1} \alpha_i x_i$.
	Let $\gamma = \max\{\frac{\alpha_i}{\beta_i} \mid i = 1, \dots, k_i, \beta_i < 0\}$
	and $\alpha_i' = \alpha_i - \gamma \beta_i$, such that $\alpha_i \geq 0$ and there exists exactly
	one $i^*$ such that $\alpha_{i^*}' = 0$.

	Note that
	\begin{equation}
		\sum \alpha_i' = \underbrace{\sum \alpha_i}_{=1} + \underbrace{\sum \gamma \beta_i}_{= 0} = 1
	\end{equation}
	But then $\sum \alpha_i' x_i = x$ since $\sum \beta_i x_i = 0$ and by our choice of $\alpha_i'$
	we know that $\alpha_{i^*}' = 0$ therefore we can remove the $i^*$-th term of the combination
	without changing the result.
	In this way we decreased $k$ by $1$.
	We can continue iteratively until $k = d+1$.
\end{proof}

\begin{theorem}{Strong convex separation}{strong-conv-sep}
	Let $C, D \subseteq \R^d$ be non-empty, convex, closed, and disjoint,
	moreover $C$ is bounded and therefore compact.
	Then, there is a hyperplane $\{x \mid a^T x = b\}$ such that
	$C \subseteq \{ \mid a^T x < b\}$ and $D \subseteq \{ x \mid a^T x > b\}$.
\end{theorem}

\begin{proof}
	Find $c \in C, d \in D$ such that $\norm{c-d}$ is minimal.
	Note that we can do this only if $C$ and $D$ are compact.
	If $D$ is also compact we are done.

	If $D$ is unbounded we choose $c'\in C, d' \in D$ and $\beta = \norm{c' - d'}$,
	$\alpha = \mathrm{diam}(C)$ (the diameter of $C$).
	Then consider the ball $B$ defined as $B = \{x \mid \norm{c' - x} \leq \alpha+\beta\}$.
	The set $D'= D \cap B$ is now compact and for $x \in C$ and $y \in D$, if $\norm{x - y} \leq \beta$,
	$y \in D'$:
	\begin{equation}
		\norm{c'-y} \leq \norm{c' - x} + \norm{x - y} \leq \alpha + \beta
	\end{equation}
	Now we choose $(c, d) = \argmin_{c \in C, d \in D'} \{\norm{c - d}\}$.

	We now choose an hyperplane using the parameters $a, b$:
	\begin{equation}
		a \coloneq d - c \quad \text{and} \quad b \coloneq \frac{a^T d - a^T c}{2}
	\end{equation}
	then
	\begin{equation}
		a^Td - a^T c = a^T a = \norm{a}^2 = \norm{d - c}^2 \geq 0
		\implies a^T d > a^T c
	\end{equation}

	Now we want to prove that $\forall x \in C: a^Tx < b$ and $\forall y \in D: a^T y > b$.
	We show that $a^T x \leq a^T c < b$ and we can do the same procedure over $D$.

	By contradiction assume that $a^Tx > a^Tc$.
	We have $a^T(x-c)>0$ which means that the angle $d, c, x$ is sharp (acuto) and we can draw
	a right-angle triangle we can form with $x' \in \mathrm{conv}(\{c, x\})$ and
	$\norm{x'-d}<\norm{c-d}$, but this contradicts the fact that $c$ is minimal.
\end{proof}


\begin{theorem}{Weak convex separation}{weak-conv-sep}
	Let $C, D$ be convex and disjoint.
	Then there is an hyper plane $\{x \mid a^T x= b\}$ such that
	$C \subseteq \{ \mid a^T x \leq b\}$ and $D \subseteq \{ x \mid a^T x \geq b\}$.
\end{theorem}

\begin{proof}
	Consider $\{0\}$ and $S = \{x - y \mid x \in C, y \in D\}$.
	Let $x - y \in S$ and $x' - y' \in S$, then take their convex combination:
	\begin{equation}
		t(x - y) + (1-t)(x'-y') =
		\underbrace{tx + (1-t)x'}_{\in C} - \underbrace{(ty + (1-t)y')}_{\in D} \in S
	\end{equation}
	Now we have a few possible cases:
	\begin{enumerate}
		\item $0 \notin \mathrm{cl}(S)$ ($0$ is in the closure of $S$).

		      We apply \cref{thm:strong-conv-sep} to $\{0\}$ and $\mathrm{cl}(S)$.
		      We have
		      \begin{equation}
			      0 = a^T 0 < b , a^T(x-y) \enspace \forall x-y \in S
			      \implies a^T x > a^T y \enspace \forall x \in C, d \in D
		      \end{equation}

		\item $0 \in \mathrm{cl}(S)$.

		      Then $0$ is in the boundary of $\mathrm{cl}(S)$.
		      \begin{enumerate}
			      \item If $\mathrm{int}(S) = \varnothing$, then $S$ belongs to a hyperplane
			            $\{x \mid a^T = 0 \}$ which we can use as separator: we have
			            $a^T x =  a^T y$ for all $x \in C, y \in D$.

			      \item If $\mathrm{int}(S) \neq \varnothing$ we define
			            $S_{-\varepsilon} = \{s \in S \mid B_\varepsilon(s) \subseteq S\}$
			            for some $\varepsilon > 0$.
			            Then $\mathrm{cl}(S_{-\varepsilon})$ is closed, convex and does not contain $0$,
			            therefore we can apply \cref{thm:strong-conv-sep}
			            and get some $a_\varepsilon, b_\varepsilon$ such that
			            $a_\varepsilon^T s > 0$ for all $s \in S_{-\varepsilon}$.

			            Now we normalize $a_\varepsilon$ such that $\norm{a_\varepsilon} = 1$
			            and choose an infinite sequence $\varepsilon_n$
			            which converges to $0$ as $n\to\infty$.
			            Since is bounded ($\norm{a_{\varepsilon_k}} = 1$) the sequence $a_{\varepsilon_n}$
			            contains a subsequence converging to $a\neq 0$.

			            Since $a_{\varepsilon_k}^T s > 0$ for all $s \in S$ and for all $k$, we have
			            $a^T s > 0$ for all $s \in \mathrm{int}$ and $a^T s \geq 0$ for all $s \in S$.
		      \end{enumerate}
	\end{enumerate}
	Therefore we have proven that $a^Ts \geq 0 \implies a^T(x-y) \geq 0$ which gives the result of
	$a^T x \geq a^T y$.
\end{proof}

\subsection{Duality}

\begin{definition}{Standard form}{lp-standard}
	Given $A \in \R^{m\cross n}, b \in \R^m, c \in \R^n$
	a linear program where the variables are $n$ dimensional and there are $m$ constraints
	can be written as
	\begin{align}
		\max c^T x & \text{ subject to} \\
		Ax \leq    & b                  \\
		x \in \R^n
	\end{align}
\end{definition}

Moreover any LP can be written in this form by adding another constraint when we have equalities,
flipping the signs of $\geq$ and of the objective function if needed.
We note that this is equivalent to finding an intersection between halpspaces, and when we require
$Ax = b$ we are instead finding an intersection between hyperplanes.

We now want to find a bound for the objective function, that is $h$ such that $c^T x \leq h$.
To do so we look for a vector $d$ such that $d_i \geq c_i$ and $h$ as small as possible.
To find such $d$ we take the constraints of the original problem and
take linear combinations of them: let $y$ be a vector in $\R^m$
(where $m$ is the number of contraints we have) and we take $y_i$ times the $i$-th constraint;
then $d_i = \sum_{j} A_{ji} y_j$.

\begin{definition}{Dual of a LP}{dual}
	In general, for a given LP in standard form (\cref{def:lp-standard}) called primal
	we can write its \emph{dual} (where $A, c, b$ are the same as primal):
	\begin{align}
		\min b^T x & \text{ subject to} \\
		A^T y =    & c                  \\
		y \geq 0
	\end{align}
\end{definition}

\subsubsection{Weak duality}

\begin{theorem}{Weak duality}{weak-duality}
	Given an LP (P) and its dual (D), for each $x$ feasible to (P) and each $y$ feasible to (D)
	we have $c^T x \leq b^y$.
\end{theorem}

\begin{proof}
	\begin{equation}
		c^T x = (A^T y)^T x = y^T A x \leq y^T b
	\end{equation}
	Where the first equality is due to $A^T y = c$ (TODO: why??) and the last inequality is because
	$Ax \leq b$ and $y \geq 0$.
\end{proof}

\begin{corollary}{}{}
	If (P) is unbounded then (D) in infeasible and viceversa.
\end{corollary}

\subsubsection{Farkas lemma}

\begin{definition}{Convex cone}{convex-cone}
	A set $C \subseteq \R^n$ is a convex cone if for all $x, y \in C$ and $\lambda, \mu \in \R^+$
	we have $\mu x + \lambda y \in C$.
\end{definition}

We call $\mathrm{cone}(X)$ the smallest cone containing $X$.

We now state some facts about convex cones without proof.

\begin{proposition}{Facts about convex cones}{facts-cones}
	The following facts are true for any convex cone:
	\begin{enumerate}[label=\roman*.]
		\item Every cone contains $0$;
		\item The smallest cone containing $X$ is
		      \begin{equation}
			      \mathrm{cone}(X) =
			      \left\{ \sum^k_{i = 1} \lambda_i x_i \mid k \in N^+, x_i \in X, \lambda_i \geq 0 \right\}
		      \end{equation}
		\item If $\abs{X}$ is finite then $\mathrm{cone}(X)$ is closed.
	\end{enumerate}
\end{proposition}

\begin{figure}[h!]
	\centering
	\includesvg[width=0.3\textwidth]{./assets/advanced-programming/convex-cone.svg}
	\caption{Two convex cones: the red one consists of all points such that $\mu x + \lambda y$.
		The curves on the top-right edge represent the region continues infinitely.}
\end{figure}

\begin{theorem}{Farkas lemma}{farkas}
	Let $a_1, \dots, a_n, b \in \R^m$ and $A = \{a_1, \dots, a_n\} \subset \R^m$.
	Then exactly one of the following cases occurs:
	\begin{enumerate}[label=\roman*.]
		\item $b \in \mathrm{cone}(A)$;
		\item There is a hyperplane passing through $0$ of the form $h = \{x \in \R^m \mid y^Tx = 0\}$
		      such that $\mathrm{cone}(A)$ is on one side of the cone
		      (i.e. $y^T a_i \geq 0$ for all $i = 1, \dots, n$) and $b$ lies on the othe side
		      (i.e $y^T b < 0$).
	\end{enumerate}
\end{theorem}

\begin{proof}
	First note that i. and ii. cannot hold at the same time, since i. implies that $y^T b \geq 0$
	but ii. implies the opposite, therefore we just need to prove that
	if i. is false then ii. is true.

	Let $C = \mathrm{cone}(A)$ and assume that $b \notin C$.
	Let $D = \{b\}$ then $D$ is compact, $C$ is closed by \cref{prop:facts-cones} and they are both
	convex, therefore we can apply \cref{thm:strong-conv-sep} to find a hyperplane
	$h' = \{ x \in \R^m \mid y^T x = \gamma\}$ such that $y^T b < \gamma$ and $y^T c > \gamma$
	for all $c \in C$. Note that since $0 \in C$ we have that $\gamma < 0$.

	Now choose $h = \{ x \in \R^m \mid y^T x = 0\}$, then $0 \in h$, $y^T b < \gamma < 0$
	therefore $b$ is on one side of $h$.
	Now we want to prove that $y^Tc \geq 0$ for all $c \in C$ so that $h$ is the hyperplane we are
	looking for.

	Assume, by contradiction, that $y^T c < 0$ for some $c \in C$.
	Then $\frac{2 \gamma}{y^T c} c \in C$ since $\frac{2 \gamma}{y^T c} \geq 0$ and
	$C$ is a convex cone.
	But then $y^T \frac{2 \gamma}{y^T c} c = 2 \gamma < \gamma$ which is a contradiction.
\end{proof}

\begin{corollary}{Farkas lemma in matrix form}{farkas-matrix}
	Let $A \in \R^{m \cross n}$ and $b \in \R^m$.
	Then exactly one of the following holds:
	\begin{enumerate}[label=\roman*.]
		\item There is $x \in \R^n$ such that $Ax = b$ and $x \geq 0$.
		\item There is $y \in \R^m$ such that $y^T A \geq 0^T$ and $y^T b < 0$.
	\end{enumerate}
\end{corollary}

\subsubsection{Strong duality}

\begin{theorem}{Strong duality}{strong-duality}
	Given a LP (P) and its dual (D) (as in \cref{def:lp-standard} and \cref{def:dual})
	exactly one of the following cases occurs:
	\begin{enumerate}[label=\roman*.]
		\item Both (P) and (D) are infeasible;
		\item (P) is unbounded and (D) is infeasible;
		\item (D) is unbounded and (P) is infeasible;
		\item Both (P) and (D) have a feasible solution, then the optimal solutions $x^*$ of (P)
		      and $y^*$ of (D) both exists and are such that $c^T x = b^T y$.
	\end{enumerate}
\end{theorem}

\section{Convex optimization}

\begin{definition}{Convex function}{convex-fn}
	Let $\mathcal D \subseteq \R^d$ convex and $f: \mathcal D \to \R$.
	Then $f$ is convex if for all $x, y \in \mathcal D$ and $\alpha \in [0, 1]$ we have
	\begin{equation}
		f(\alpha x + \overline{\alpha} y) \leq \alpha f(x) + \overline \alpha f(y)
	\end{equation}
	where $\overline \alpha = (1-\alpha)$.
\end{definition}

As we know that a differentiable $f$ is convex if and only if its domain is convex and
\begin{equation}
	f(y) \geq f(x) + \grad f(x)^T(y-x)
\end{equation}
that is, its first order approximation is smaller than the value itself.
This is quite useful because it tells us that if $\grad f(x) = 0$ we have found a local minimum.


\begin{definition}{Convex program}{convex-program}
	Let $\mathcal D \subseteq \R^n$ convex and $f_0, f_1, \dots, f_m, h_1, \dots, h_p: \mathcal D \to \R$
	be convex functions.
	The following minimization problem is a convex program in standard form:
	\begin{align}
		\min f_0(x)         &                              \\
		\text{s.t. }	f_i(x) & \leq 0 \quad i = 1, \dots, m \\
		h_i(x)              & = 0    \quad i = 1, \dots, p
	\end{align}
\end{definition}

\begin{definition}{Lagrangian}{lagrangian}
	A function $L: (\mathcal D \cross \R^m \cross \R^p) \to \R$ is the lagrangian of a convex
	program if
	\begin{equation}
		L(x, \lambda, \nu) = f_0(x) + \sum_{i = 1}^m \lambda_i f_i(x) + \sum_{i = 1}^p \nu_i h_i(x)
	\end{equation}
	where $\lambda_i, \nu_i$ are called \emph{lagrangian multipliers}, while
	the vectors $\vec \lambda, \vec \nu$ are called \emph{dual variables}.
\end{definition}

Using the lagrangian we can express the primal as
\begin{equation}
	p^* = \inf_{x \in \mathcal D} \sup_{\substack{\lambda \geq 0 \\ \nu}} L(x, \lambda, \nu)
\end{equation}
and the dual as
\begin{equation}
	q^* = \sup_{\substack{\lambda \geq 0 \\ \nu}} \inf_{x \in \mathcal D} L(x, \lambda, \nu)
\end{equation}

\begin{definition}{Lagrangian dual}{lagrangian-dual}
	The lagrangian dual problem (or just dual) of a convex optimization problem is defined as
	\begin{align}
		\max_{\lambda, \nu} \left(\inf_{x\in \mathcal D} L(x, \lambda, \nu) \right) &        \\
		\text{s.t. }	\lambda                                                        & \geq 0
	\end{align}
	where $L$ is the lagrangian of the primal as defined in \cref{def:lagrangian}.
\end{definition}

TODO: weak duality holds, see lecture 7.

However strong duality does not: in fact we can construct a counter example where
the optimal solutions exist and do not coincide.
Consider the following program over the domain $\mathcal D = \{(x, y) \mid y \geq 0 \}$
\begin{align}
	\min e^{-x} & \\
	\text{s.t. }	\frac{x^2}{y} \leq 0
\end{align}
We have that the optimal objective value is $e^0 = 1 = p^*$ with $x^* = 0$.
The lagrangian is $L(x, y, \lambda) = e^{-x} + \lambda \frac{x^2}{y}$
and the dual function is $g(\lambda) = \inf_{x, y \gt 0} (e^{-x} + \lambda x^2/y)$
which is $0$ if $\lambda \geq 0$ and $-\infty$ if $\lambda < 0$.
Then the solution to the dual is $\max_{\lambda \geq 0} g(\lambda) = 0 = d^*$
and $p^* \neq d^*$.

We want to find another condition to add to the strong duality theorem for it to hold
even in convex programs.

\subsection{Slater's constraints}

\begin{theorem}{Slater's theorem}{slaters}
	Consider the following convex program
	\begin{align}
		\min f_0(x)         &                              \\
		\text{s.t. }	f_i(x) & \leq 0 \quad i = 1, \dots, m \\
		A x                 & = b
	\end{align}
	such that $x \in \mathrm{int}(\mathcal D)$ and $f_i \lt 0$ for all $i = 1, \dots, m$ where
	$f_i$ is not affine.
	Note that all the $h_i$ are affine and can therefore be summarized as a matrix.

	Then strong duality holds (cf. \cref{thm:strong-duality}).
\end{theorem}

Note that these conditions these are not the only conditions for strong duality to hold, we will
discuss more in the future.
Moreover, Slanter's conditions ensure that an optimal solution exists.
These conditions are automatically satisfied by linear programs.

\begin{proof}
	Consider the following sets:
	\begin{align}
		\mathcal G & = \{ (f_0(x), f_1(x), \dots, f_m(x), h_1(x), \dots, h_p(x)) \mid x \in \mathcal D\} \\
		\mathcal A & = \left\{ (u, v, t) \mid \exists x \in \mathcal D \text{ s.t. }
		\substack{f_i(x) \leq u_i \enspace \forall i = 1, \dots, m                                       \\
		h_i(x) = v_i \enspace \forall i = 1, \dots, p                                                    \\
			f_0(x) \leq t
		} \right\}
	\end{align}

	Then we can write the optimal solution for the primal equivalently as
	\begin{align}
		p^* & = \inf \{ t \mid (u, v, t) \in \mathcal G, u \leq 0, v = 0\} \\
		    & = \inf \{ t \mid (0, 0, t) \in \mathcal A\}
	\end{align}
	We can also write the dual function as
	\begin{align}
		g(\lambda, \nu) & = \inf \{(\lambda, \nu, 1)^T(u, v, t) \mid (u, v, t) \in \mathcal G \} \\
		                & = \inf \{(\lambda, \nu, 1)^T(u, v, t) \mid (u, v, t) \in \mathcal A \}
	\end{align}
	where we notice that $(\lambda, \nu, 1)^T(u, v, t)$ is the lagrangian.

	The next step is to prove that $\mathcal A$ is convex.
	To do so we consider $(u, v, t) = x, (u', v', t') = x' \in \mathcal A$
	and $\tau \in [0, 1]$.
	We want to show that $\overline x = \tau (u, v, t) + \overline \tau(u', v', t') \in \mathcal A$.
	\begin{align}
		f_0(\overline x) & \leq \tau t + \overline \tau t     & \text{by convexity of } f_0 \\
		f_i(\overline x) & \leq \tau u_i + \overline \tau u_i & \text{by convexity of } f_i \\
		h_i(\overline x) & \leq \tau v_i + \overline \tau v_i & \text{by affinity of } h_i
	\end{align}
	therefore $\overline x \in \mathcal A$.

	Now we are ready to prove the actual theorem.
	We assume $\mathrm{rank}(A) = p$ (otherwise we remove the redundant constraints).
	If $p^* = -\infty$ by weak duality also $d^* = -\infty$, hence we just need to consider the cases
	where $p^*$ is finite.
	Let us define another set
	\begin{equation}
		\mathcal B = \{(0,0,s) \in \R^m \cross \R^n \cross \R \mid s < p^* \}
	\end{equation}
	then $\mathcal A \cap \mathcal B = \varnothing$ since otherwise it would imply that
	there exists a feasible $x \in \mathcal D$ and $f_0(x) = t < p^*$ which contradicts the fact that
	$p^*$ is optimal.

	Since they are both convex we use \cref{thm:weak-conv-sep} to find a hyperplane
	$h = \{(u, v, t) \mid (\overline \lambda, \overline \nu, \mu)^T (u, v, t) = \alpha \}$
	such that
	\begin{align}
		\overline \lambda^T u + \overline \nu^T v + \mu t & \geq \alpha \quad \forall (u, v, t) \in \mathcal A \\
		\overline \lambda^T u + \overline \nu^T v + \mu t & \leq \alpha \quad \forall (u, v, t) \in \mathcal B
	\end{align}
	then for every $x \in \mathcal D$ we have
	\begin{equation}
		\sum_{i = 1}^m \lambda_i f_i(x) + \overline \nu^T(Ax - b) + \mu f_0(x) \geq \alpha \geq \overline \mu p^*
		\label{eq:weird-lagrangian}
	\end{equation}
	which is very similar to the lagrangian with an extra $\mu$ term.

	Now we consider two cases based on $\mu$:
	\begin{enumerate}[label=\roman*.]
		\item $\mu > 0$. We divide everything by $\mu$ to get the lagrangian
		      \begin{equation}
			      L(x, \lambda, \nu) =
			      L\left( x, \frac{\overline \lambda}{\mu}, \frac{\overline \nu}{\mu} \right)
			      \geq p^*
		      \end{equation}
		      which means $g(\lambda, \nu) \geq p^*$ and since $g(\lambda, \nu)\leq p^*$ already holds
		      by weal duality we conclude that $g(\lambda, \nu) = p^*$ and $(\lambda, \nu)$ is the
		      optimal solution to the dual.
		\item $\mu = 0$.
		      The idea is that we have that
		      $h = \{(u, v, t) \mid (\overline \lambda, \overline \nu, 0)^T (u, v, t) = \alpha \}$
		      which means that the plane is vertical since it does not depend on $t$.

		      If we substitute $\mu = 0$ in \cref{eq:weird-lagrangian} we get
		      \begin{equation}
			      \sum_{i = 1}^m \lambda_i f_i(x) + \overline \nu^T(Ax - b)  \geq 0
		      \end{equation}
		      Now we apply feasibility, that is $Ax - b = 0$, to get
		      \begin{equation}
			      \sum_{i = 1}^m \lambda_i f_i(x) \geq 0
		      \end{equation}
		      but by Slater's conditions we have that $f_i(\overline x) < 0$,
		      therefore $\overline \lambda = 0$.

		      Then our hyperplane, which is defined by $(\overline \lambda, \overline \nu, \mu)$, needs
		      to be $\neq 0$, since $0$ does not define an hyperplane: necessarily we have that
		      $\overline \nu \neq 0$.

		      From before we know that $\overline \nu^T (Ax - b) = 0$ which fives us two cases:
		      \begin{itemize}
			      \item If $\overline \nu^T A \neq 0$ then there exists $x \in \mathcal D$ such that
			            $\overline \nu^T(Ax - b) < 0$;
			      \item If $\overline \nu^T A = 0$ then $A$ has some linearly dependent rows.
		      \end{itemize}
		      In both cases we have reached a contradiction, therefore $\mu$ cannot be $0$.
		      \qedhere
	\end{enumerate}
\end{proof}

\begin{example}{Least squares}{least-squares}
	Write the dual of the following convex problem:
	\begin{align}
		\min x^T x       &     \\
		\text{s.t. }	A x & = b
	\end{align}
\end{example}

\begin{proof}[Solution]
	The lagrangian is
	\begin{equation}
		L(x, \nu) = x^T x + \nu^T (Ax - b)
	\end{equation}
	(notice we do not have $\lambda$.)
	Now we want to minimize the lagrangian w.r.t. $x$: since it is differentiable we can solve
	$\grad_x L(x, \nu) = 0$, that is
	\begin{equation}
		2x + A^T \nu = 0 \implies x = - \frac{A^T \nu}{2}
	\end{equation}
	then the dual can be written as
	\begin{equation}
		\max_{\nu} \left(-\frac{1}{4}\right) \nu^T A A^T \nu - b^T \nu
	\end{equation}
\end{proof}

\subsection{KKT Conditions}
In linear programming we had some ways to check whether a solution was optimal.
In convex programming we have something similar.

\begin{theorem}{KKT}{kkt-cond}
	Consider a convex problem as in \cref{def:convex-program} where $f_0, f_1, \dots, f_m, h_1, \dots, h_p$
	are differentiable.
	Let $x^*$ be a solution to the primal and $(\lambda^*, \nu^*)$ a solution to the dual.
	Then $x^*$ and $(\lambda^*, \nu^*)$ are optimal and $d^* = p^*$ if and only if all the following
	conditions are true:
	\begin{enumerate}[label=(\roman*.)]
		\item $f_i(x^*) \leq 0 \enspace \forall i = 1, \dots, m$
		\item $h_i(x^*) = 0 \enspace \forall i = 1, \dots, p$
		\item $\lambda_i^* \geq 0 \enspace \forall i = 1, \dots, m$
		\item $\lambda^*_i f_i(x^*) = 0 \enspace \forall i = 1, \dots, m$
		\item $\grad f_0(x^*) + \sum \lambda_i^* \grad f_i(x^*) + \sum \nu_i^* \grad h_i(x^*) = 0$
	\end{enumerate}
\end{theorem}

\begin{proof}
	We prove each implication separately.
	\begin{description}
		\item[Optimality implies KKT conditions]
		      Conditions (i.), (ii.), and (iii.) are true since they are implied
		      by the feasibility of the primal and the dual.

		      To show (iv.) and (v.) we use the fact that we have optimal solutions:
		      \begin{align}
			      f_0(x^*) & = g(\lambda^*, \nu^*)                                                                                            \\
			               & = \inf_{x} f_0(x) + \sum \lambda_i^* f_i(x) + \sum \nu_i^* h_i(x)                                                \\
			               & \cancelto{=}{\leq} f_0(x^*) + \cancelto{\leq 0}{\sum \lambda_i^* f_i(x^*)} + \cancelto{0}{\sum \nu_i^* h_i(x^*)} \\
			               & \cancelto{=}{\leq} f_0(x^*)
		      \end{align}
		      where we put $=$ instead of $\leq$ since $x^*$ is minimizer of the lagrangian and
		      the last equality holds because (by feasibility) we have that $\lambda_i^* \geq 0$
		      and $f_i(x^*) \leq 0$.
		      This proves (v.) and (iv.) comes from the fact that $\sum \lambda_i^* f_i(x^*) = 0$
		      and every term is non-positive.
		\item[KKT conditions imply optimality]
		      Conditions (i.), (ii.) and (iii.) imply feasibility of the primal and the dual.

		      Since $\lambda_i \geq 0$, $L$ is the sum of convex functions so it is also convex.
		      Moreover, we use (v.), which tells us that $x^*$ is a minimizer, to write
		      \begin{align}
			      g(\lambda^*, \nu^*) & = L(x^*, \lambda^*, \nu^*)                                                                   \\
			                          & = f_0(x^*) + \cancelto{= 0}{\sum \lambda_i^* f_i(x^*)} + \cancelto{0}{\sum \nu_i^* h_i(x^*)} \\
			                          & = f_0(x^*)
		      \end{align}
		      where we cancelled the first term using (iv.) and the second one by feasibility.
		      \qedhere
	\end{description}
\end{proof}

\end{document}
