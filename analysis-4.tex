\documentclass[12pt]{extarticle}

\setlength{\headheight}{16pt} % ??? we do what fancyhdr tells us to do  

\title{Analysis 4}
\author{Giacomo Ellero}
\date{a.y. 2024/2025}

\usepackage{preamble}

\renewcommand{\vec}[1]{\uvec{#1}}

\begin{document}
\oldfirstpage

The first part of the course will be about complex analysis and the second one will be about
differential geometry.

\section{Complex analysis}

Naively we can start by replacing $\R$ with $\C \approxeq \R^2$.
A lot things carry over from real analysis but \emph{complex differentiable} functions have
many more interesting properties.

\subsection{Constructing complex numers}

\subsubsection{The boring way}
The \say{boring} definition of complex number is a set $\C \supseteq \R$ where $\sqrt{-1}$ exists
and is defined as $i$ and $-i$.
Formally, this is the smallest \emph{field} where we include $\R$ and $i$.

A complex number $z$ can be written as
\begin{equation}
	z = a + bi \in \C \quad \text{with } a, b \in \R
\end{equation}

This representation is useful since it has a bunch of nice properties:
\begin{itemize}
	\item It is closed under multiplication;
	\item We define the complex conjugate $\overline{a + bi} = a - bi$ and
	      if we multiply $z$ with $\overline z$ we get a real number;
	\item We define a norm over $\C$ as $\norm{z} = z \overline z$;
	\item There exists an inverse, that is for each $z = a + bi \neq 0$
	      (i.e. either $a$ or $b$ $\neq 0$) we can define
	      \begin{equation}
		      z^{-1} = \frac{\overline z}{\norm{z}^2}
	      \end{equation}
\end{itemize}

Now we can formally say that $a + bi$ is the formal expression of a number in $\C$,
define the sum as the usual sum in $\R^2$ and the product as
\begin{equation}
	(a, b) \cdot (c, d) = (ac - bd, ad + bc)
\end{equation}
and we are able to prove that this is commutative and associative,
the proof is long and boring therefore we skip it.

\subsubsection{Geometric construction}

First we start with a simple lemma about isometries.

\begin{lemma}{Isometries that fix the origin are linear maps}{}
	Consider an isometry $f: \R^n \to \R^n$,
	that is $\abs{f(p) - f(q)} = \abs{p-q}$ for all $p, q \in \R^2$.
	If $f(0) = 0$, then $f$ is linear and we can write $f(v) = Av$
	where $A \in O(n)$ is an orthogonal $n\cross n$ matrix, that is $A^{-1} = A^T$.
\end{lemma}

In dimension $n = 2$ we can explicitly write a matrix $A$ which rotates the plane counterclockwise
by an angle $\theta$ as
\begin{equation}
	A = \begin{pmatrix}
		\cos \theta & -\sin \theta \\
		\sin \theta & \cos \theta
	\end{pmatrix}
\end{equation}
Rotation matrices form a subset of $O(n)$, namely those with $\det = 1$.

On the other hand, we define a \emph{homothety} or \emph{dilation} as the linear maps which
can be written as $f = \rho I$, with $\rho \geq 1$.
Now we can combine rotations and dilations to obtain a set of matrices of the form
\begin{align}
	\mathcal C & = \left\{ A = \rho I \cdot R_\theta \mid \rho \geq 0, \theta \in \R\right\} \\
	           & =  \left\{ A = \begin{pmatrix}
		                            \rho \cos \theta & - \rho \sin \theta \\
		                            \rho \sin \theta & \rho \cos \theta
	                            \end{pmatrix}
	\mid \rho \geq 0, \theta \in \R\right\}                                                  \\
	           & = \left\{ A = \begin{pmatrix}
		                           a & -b \\
		                           b & a
	                           \end{pmatrix}
	\mid a, b \in \R\right\}
\end{align}
We notice that $\mathcal C$ is a vector space of matrices of dimension 2 with bases
$I$ (the identity matrix) and $J = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$.

We can now draw a parallel between $\mathcal C$ and $\C$:
$I$ corresponds to $1$ and $J$ corresponds to $i$.

We can now write a formal definition using the matrices:
the sum and the product is the same as in matrices,
note that this set is closed under multiplication as $J ^2 = -I$.
Moreover we get for free that the product is associative (since it is that way with matrices)
and since $IJ = JI$ it is also commutative.

\subsection{Complex differentiability}
We will identify $\C \approxeq \R^2$ so that we get for free the definition of open and closed sets.

\begin{remark}{Product of complex numbers as a matrix}{}
	We can prove that identifying two complex numbers as pairs in $\R^2$ we get
	\begin{equation}
		(a, b) \cdot (c, d) = \begin{pmatrix} a & -b \\ b & a \end{pmatrix}
		\begin{pmatrix} c \\d \end{pmatrix}
	\end{equation}
\end{remark}

Now we can define complex differentiability:
\begin{definition}{Complex differentiability}{}
	Let $U \in \C$ open, $f: U \to \C$ be a function and $z_0 \in U$.
	We say that $f$ is complex differentiable at $z_0$ if
	\begin{equation}
		f(z) = f(z_0) + \alpha (z-z_0) + \o(\abs{z -z_0})
	\end{equation}
	for some $\alpha \in \C$ or equivalently
	\begin{equation}
		f'(z_0) \coloneq \lim_{z \to z_0} \frac{f(z) - f(z_0)}{z - z_0} = \alpha \in \C
	\end{equation}
	exists for some $\alpha$.
\end{definition}
Basically this definition tells us that $f$ is complex differentiable
if the first order taylor expansion exists and is linear.

\begin{definition}{Holomorfic function}{}
	A function $f: U \to \C$ is holomorfic if it is complex differentiable at every $z_0 \in U$.
\end{definition}

\begin{proposition}{Cauchy-Riemann equations}{}
	$f$ is complex differentiable at $z_0 \in U$ $\iff$
	$Df(z_0) = \begin{pmatrix} a & -b \\ b & a \end{pmatrix}$ for some $a, b \in \R$, in which case
	$f'(z_0) = a + bi$.

	Equivalently we can say that there exists $g, h: \R \to \R$ that satisfy
	\begin{equation}
		\begin{cases}
			\pdv{g}{x}()(z_0) = \pdv{h}{y}()(z_0) \\
			\pdv{h}{z}()(z_0) = -\pdv{g}{y}()(z_0)
		\end{cases}
	\end{equation}
	and
	\begin{equation}
		f(z) = f(x + yi) = g(x+yi) + h(x+yi)i
	\end{equation}
\end{proposition}

\begin{proof}
	This is actually quite easy, just see $f$ as a function from and to $\R^2$.
	Now we can compute the differential the usual way and if we want it to look like
	$\begin{pmatrix} a & -b \\ b & a \end{pmatrix}$
	we have to impose the two equations above.
\end{proof}

\subsection{Cauchy integral theorem}

In this section we will discuss and prove Cauchy integral theorem.
We will assume $U$ to be an open subset of $\C$.

\subsubsection{Integration over \texorpdfstring{$\C$}{C}}

\begin{definition}{Piecewise $C^1$ curve}{piecewise-c1}
	A function of the form $\gamma: [s, t]: U$ with $U$ and $s \leq t \in \R$
	is piecewise $C^1$ if for some suitable $s = t_0 < t_1 < \dots < t_N = t$
	the restriction $\eval{\gamma}_{[t_{j-1}, t_j]}$ is of class $C^1$ for all $j = 1, \dots, N$.

	Moreover, we say $\gamma$ is a \emph{loop} if $\gamma(s) = \gamma(t) = z_0$ and we call $z_0$ the
	\emph{basepoint} of the loop.
\end{definition}

\begin{definition}{Line integral}{line-integral}
	Given a continuous function $f: U \to \C$ and a piecewise $C^1$ curve $\gamma$ in $U$ we define the line
	integral of $f$ along $\gamma$ as
	\begin{equation}
		\int_\gamma f(z) \dd z \coloneq
		\sum_{j = 1}^N \int_{t_{j-1}}^{t_j} f(\gamma(\tau)) \cdot \gamma'(\tau) \dd{\tau}
	\end{equation}
\end{definition}

\begin{proposition}{Reparametrization independence}{reparametrization}
	Let $\gamma: U \to [s, t]$ and $\varphi: [s, t] \to [s', t']$ strictly increasing and both
	piecewise $C^1$.
	Let $\delta = \gamma \circ \varphi$, then, for all $f$ continuous,
	\begin{equation}
		\int_\gamma f(z) \dd z = \int_\delta f(z) \dd z
	\end{equation}
\end{proposition}
\begin{proof}
	This is the result of applying the change of variable formula with $z'= \varphi(z)$
	together with the chain rule.
\end{proof}

From now on we will often describe a loop by just its shape and it's orientation, without specifying
the parametrization or the basepoint, since, as we just saw, the integral does not depend on those.

\subsubsection{Cauchy integral theorem special form}

TODO: lec 3

\begin{theorem}{Cauchy integral theorem for rectangles}{cauchy-integral-rect}
\end{theorem}

\subsubsection{Local primitives}

\begin{definition}{Connected set}{connected-set}
	A non-empty set $V \subseteq \C$ is connected if
	$\nexists S_1, S_2 \in V$ open with $S_1, S_2 \neq \varnothing$,
	$V = S_1 \cup S_2$ and $S_1 \cap S_2 = \varnothing$.
\end{definition}

We note that a set is connected if and only if given $p, q \in V$ we can find $\gamma: [s, t] \in V$
continuous such that $\gamma(s) = p$ and $\gamma(t) = q$.
Moreover, if we have a family of connected sets $V_j$ such that they have a point in common, then
their union is still connected.

\begin{definition}{Local primitive}{local-primitive}
	Let $f: U \to \C$ holomorfic and $V \subseteq U$ open and connected.
	Then $F: V \to \C$ is a local primitive of $f$ on $V$ if
	\begin{equation}
		F' = f
	\end{equation}
\end{definition}

\begin{proposition}{Uniqueness of local primitives}{uniq-local-prim}
	Two local primitives $F_1, F_2: V \to \C$ of the same $f$, defined on the same $V \subseteq U$
	are unique up to a constant.
\end{proposition}

This is the same behavior we observe for primitives over $\R$.

\begin{proof}
	Let $H = F_2 - F_1$, we want to prove that $H$ is constant.
	Let $\lambda \in H(V)$ be one of the values assumed by $H$, then
	\begin{equation}
		V = \{ z \in V : H(z) = \lambda \} \cup \{ z \in V : H(z) \neq \lambda \}
	\end{equation}
	This is a disjoint union and we claim that the sets are both open, hence, since $V$ is connected,
	one of the two must be empty.
	We know that $\{ z \in V : H(z) = \lambda \} \neq \varnothing$ therefore necessarily
	$\{ z \in V : H(z) \neq \lambda \} = \varnothing$ and $\lambda$ is the only value assumed by $H$.

	Now, $\{ z \in V : H(z) \neq \lambda \}$ is open because it is the preimage of an open set
	($\C \setminus \lambda$) through a continuous function
	($H$ is holomorfic and therefore continuous).

	To show that $\{ z \in V : H(z) = \lambda \}$ is open we fix a point $z_0 \in V$ such that
	$H(z_0) = \lambda$. Since $V$ is open we can find $B_r(z_0) \in V$ and we will show that
	$H(B_r(z_0)) = \lambda$ which is enough to conclude that $\{ z \in V : H(z) = \lambda \}$ is open.
	To prove this we use the fact that $H' = f - f = 0$ and viewing it as a function from $\R^2$ to
	$\R^2$ we get that $DH(z) = 0$ everywhere.
	Now we consider $z_1 \in B_r(z_0)$ and we let $\gamma: [0,1] \to B_r(z_0)$ be the parametrization
	of the segment from $z_0$ to $z_1$:
	\begin{equation}
		\gamma(t) = H(z_0 + t(z_1 - z_0))
	\end{equation}
	and by the chain rule we have that
	\begin{equation}
		(H\circ \gamma)'(t) = DH(\gamma(t)) [\gamma'(t)] = 0
	\end{equation}
	Thus $H \circ \gamma: [0, 1] \to \R^2$ is a function with zero derivative at each point,
	which means that
	\begin{equation}
		H(z_1) = H(\gamma(1)) = H(\gamma(0)) = H(z_0) = \lambda
	\end{equation}
	as desired.
\end{proof}

\subsubsection{Integration over piecewise \texorpdfstring{$C^1$}{C1} curves}

\begin{proposition}{Fundamental theorem of calculus for curves}{fundamental-curves}
	Given a local primitive $F: V \to \C$ of $f$ and a piecewise $C^1$ curve $\gamma: [s, t] \to V$
	we have
	\begin{equation}
		\int_\gamma f(z) \dd z = F(\gamma(t)) - F(\gamma(s))
	\end{equation}
\end{proposition}

\begin{proof}
	Let $s = t_0 < t_1 < \dots < t_N = t$ such that the restriction $\eval{\gamma}_{[t_{j-1}, t_j]}$
	is $C^1$ for all $j = 1, \dots, N$.
	The usual proof of the chain rule gives us that
	\begin{equation}
		\dv{\tau} (F\circ \gamma)(\tau) = F'(\gamma(\tau)) \cdot \gamma'(\tau)
	\end{equation}
	where the lat $\cdot$ is the product of complex numbers.

	Since $F' = f$ we get
	\begin{align}
		\int_\gamma f(z) \dd z
		 & = \sum^N_{j = 1} \int^{t_j}_{t_{j-1}} f(\gamma(\tau)) \cdot \gamma'(\tau) \dd \tau  \\
		 & = \sum^N_{j = 1} \int^{t_j}_{t_{j-1}} F'(\gamma(\tau)) \cdot \gamma'(\tau) \dd \tau \\
		 & = \sum^N_{j = 1} \int^{t_j}_{t_{j-1}} (F\circ \gamma)'(\tau) \dd \tau               \\
		 & = \sum^N_{j = 1} [F \circ \gamma(t_j) - F \circ \gamma(t_{j-1})]                    \\
		 & = F \circ \gamma(t) - F \circ \gamma(s)
	\end{align}
	where we have used the fundamental theorem of calculus and
	the fact that the last sum is telescopic.
\end{proof}

\begin{corollary}{}{}
	If a local primitive $F: V \to \C$ exists and $\gamma: [s, t] \to V$ is a piecewise $C^1$ loop
	we have
	\begin{equation}
		\int_\gamma f(z) \dd z = 0
	\end{equation}
\end{corollary}
\begin{proof}
	Follows from the proposition since $F(\gamma(t)) = F(\gamma(s))$.
\end{proof}

\subsubsection{Local primitives in a ball}

We will now show that a local primitive always exists within open balls
(often called disks when over $\C$).

We will also introduce the following notation:
\begin{itemize}
	\item Given two curves $\eta$ and $\beta$ we indicate with $\eta * \beta$ the concatenation
	      of two curves such that
	      \begin{equation}
		      \int_{\eta * \beta} f(z) \dd z = \int_\eta f(z) \dd z + \int_\beta f(z) \dd z
	      \end{equation}
	\item We denote $[p, q]$ any parametrization of the segment that connects the two points $p, q$.
	      A standard parametrization is $\tau \mapsto p + \tau(q-p)$ with $\tau \in [0, 1]$.
\end{itemize}

\begin{proposition}{Existence of local primitives in a ball}{existence-local-primitive}
	Let $f: U \to \C$ holomorfic and $V = B_r(z_0) \subseteq U$ be an open ball.
	Then there exists a local primitive $F(z)$ for all $z \in V$.
\end{proposition}

\begin{proof}
	Let $z \in V$ and $a + bi = z - z_0$, consider two piecewise $C^1$ curves $\gamma, \delta$
	defined as
	\begin{align}
		\gamma & = [z_0, z_0 + bi] * [z_0 + bi, z] \\
		\delta & = [z_0, z_0 + a] * [z_0 + a, z]
	\end{align}
	that is, both curves start at $z_0$ and reach $z$ but
	$\gamma$ travels first vertically then horizontally while
	$\delta$ travels first horizontally and then vertically.

	Let $\alpha = \delta * \gamma^{-1}$ be the concatenation of $\delta$ and the \emph{reverse} of
	$\gamma$, that is, $\alpha$ parametrizes the boundary of the rectangle $R$ with vertices
	$\{z_0, z_0 + a, z_0 + bi, z\}$.
	This gives
	\begin{equation}
		\int_\delta f(w) \dd w - \int_\eta f(w) \dd w = \int_{\partial R} f(z) \dd z = 0
	\end{equation}
	by \cref{thm:cauchy-integral-rect} which we have already proven. Also note that all $w \in R$ are
	also included in $V$.
	Now, since their difference is $0$, we can let $F(z)$ be the common value of these two integrals:
	\begin{equation}
		F(z) = \int_\delta f(w) \dd w = \int_\eta f(w) \dd w
	\end{equation}

	Interpreting $F$ as a map of the form $F: \R^2 \to \C$, we have
	\begin{equation}
		\pdv{F}{x}()(z) = \lim_{\varepsilon \to 0} \frac{F(z + \varepsilon) - F(z)}{\varepsilon}
	\end{equation}
	where $\varepsilon \in \R$.
	Now if we consider the definition of $F$ using $\gamma$, we have
	\begin{align}
		F(z + \varepsilon) & = \int_{[z_0, z_0 + ib] * [z_0 + ib, z + \varepsilon]} f(w) \dd w          \\
		                   & = \int_{[z_0, z_0 + ib] * [z_0 + ib, z] * [z, z + \varepsilon]} f(w) \dd w \\
		                   & = \int_{[z_0, z_0 + ib] * [z_0 + ib, z]} f(w) \dd w
		+ \int_{[z, z + \varepsilon]} f(w) \dd w                                                        \\
		                   & = F(z) + \int_{[z, z + \varepsilon]} f(w) \dd w
	\end{align}
	then we choose $\tau \mapsto z + \tau \varepsilon$ as our parametrization of $[z, z + \varepsilon]$
	so that $\dv{\tau} (z + \tau \varepsilon) = \varepsilon$.
	We get
	\begin{equation}
		F(z + \varepsilon) - F(z) = \int_0^1 f(z + \tau \varepsilon) \cdot \varepsilon \dd \tau
		= \int_0^\varepsilon f(z + \sigma) \dd{\sigma}
	\end{equation}
	where we have used the change of variable $\sigma = \tau \varepsilon$.
	Then, since $f$ is continuous, (and???)
	\begin{equation}
		\pdv{F}{x}()(z) = \lim_{\varepsilon \to 0} \frac{1}{\varepsilon}
		\int_0^\varepsilon f(z + \sigma) \dd \sigma = f(z)
	\end{equation}

	Similarly for the imaginary part we have
	\begin{equation}
		\pdv{F}{y}()(z) = \lim_{\varepsilon \to 0} \frac{1}{\varepsilon}
		\int_0^\varepsilon f(z + i \sigma) \cdot i \dd \sigma = f(z) \cdot i
	\end{equation}
	where the additional $i$ comes from the fact that now the extra piece we are integrating over is
	$[z, z + i \varepsilon]$.

	We have just showed that $F$ admits a derivative at any point $z \in V$ and it is continuous,
	since $f$ is continuous, therefore, we can invoke the powers of multivariate calculus to say that
	$F$ is indeed differentiable and of class $C^1$.
	Moreover if we write $f(z) = \alpha + i \beta$ we have
	\begin{align}
		\pdv{F}{x}()(z) & = \alpha + i \beta  \\
		\pdv{F}{y}()(z) & = - \beta + i\alpha
	\end{align}
	which means that $F$ satisfies Cauchy-Riemann equations therefore $F$ is holomorfic
	and $F'(z) = f(z)$ for all $z \in V$.
\end{proof}

\subsubsection{Integration over continuous curves}

We now state a more general result for integrating over all continuous curves
(not just those which are piecewise $C^1$).

\begin{proposition}{Line integral over a continuous curve}{integral-continuous-curve}
	Let $f: U \to C$ holomorfic and $\gamma: [s, t] \to U$ continuous,
	then there exists a subdivision $s = t_0 < t_1 \dots < t_N = t$ such that
	for each $j = 1, \dots, N$ the image of $\gamma([t_{j-1}, t_j])$ is included in the domain
	$V_j \subseteq U$ of some local primitive $F_j: V \to \C$ of $f$.

	Moreover,
	\begin{equation}
		\int_\gamma f(z) \dd z = \sum_{j = 1}^N [F_j(\gamma(t_j)) - F_j(\gamma(t_{j-1}))]
	\end{equation}
	and this value does not depend on the choice of the subdivision, of $V_j$ or of $F_j$.
\end{proposition}

\begin{proof}
	If $U = \C$ we can just take $N = 1$ and $V_1$ be any ball included in the image of $\gamma$.

	Otherwise we let $\rho: \C \to \R$ be the function that assigns to each $z \in \C$ the distance to
	$\C \setminus U$, that is
	\begin{equation}
		\rho(z) = \inf_{w \in \C \setminus U} \abs{z - w}
	\end{equation}
	Moreover, by the triangle inequality we have that $\rho(z') \leq \abs{z-z'} + \rho(z)$
	and interchanging the roles of $z$ and $z'$ we get $\abs{\rho(z') - \rho(z)} \leq \abs{z' - z}$
	which means that $\rho$ is Lipschitz continuous.
	Furthermore, since $U$ is open, $\rho$ is positive on $U$, thus we can let
	\begin{equation}
		r = \min_{\tau \in [s, t]} \rho(\gamma(\tau))) > 0
	\end{equation}
	Now, since $\gamma$ is continuous and its domain is compact it is also uniformly continuous,
	thus, for some $N$ large enough, we have
	\begin{equation}
		\abs{\gamma(\tau) - \gamma(t_j)} < r \quad \text{for } \tau \in [t_{j-1}, t_j],
		\quad \text{with } t_j = s + j \frac{t-s}{N}
	\end{equation}
	which means we can take $\gamma(t_j)$ as the center of the ball $V_j$ with radius $r$, which is
	guaranteed to be included in $U$ since $r \leq \rho(\gamma(t_j))$,
	and invoking \cref{prop:existence-local-primitive} we obtain a local primitive $F_j$.

	TODO: idk about the second part of the proof, too hard for now.
\end{proof}

Moreover, this definition is coherent with the one over $C^1$ curves.

\subsubsection{Invariance under homotopies}

\begin{definition}{Homotopy}{homotopy}
	Given two curves $\gamma_0: [s, t] \to U$ and $\gamma_1: [s, t] \to U$ with the same endpoints
	$p = \gamma_0(s) = \gamma_1(s)$ and $q = \gamma_0(t) = \gamma_1(t)$, a homotopy is a
	\emph{continuous} function
	\begin{equation}
		\Gamma: [0,1]\cross[s, t] \to U
	\end{equation}
	such that $\Gamma(0, \cdot) = \gamma_0$, $\Gamma(1, \cdot) = \gamma_1$, and
	for all $\lambda \in [0,1]$ we have that $\Gamma(\lambda, \cdot)$
	is a curve with endpoints $p, q$.
	That is $\Gamma$	interpolates between the two curves.

	If such function exists we say that $\gamma_0, \gamma_1$ are \emph{homotopic}
	and we write $\gamma_0 \simeq \gamma_1$.
\end{definition}

\begin{theorem}{Invariance under homotopies}{invariance-homotopies}
	Let $f: U \to \C$ holomorfic and two curves such that $\gamma_0 \simeq \gamma_1$.
	Then
	\begin{equation}
		\int_{\gamma_0} f(z) \dd z = \int_{\gamma_1} f(z) \dd z
	\end{equation}
\end{theorem}

\begin{proof}
	Assume that $s = 0$ and $t = 1$ (which we can obtain by reparametrizing the curves which remain
	homotopic) and let $\Gamma: [0,1]\cross[0,1]$ be an homotopy between $\gamma_0$ and $\gamma_1$.

	With a similar argument as the beginning of the proof of \cref{prop:integral-continuous-curve},
	for some $N$ large enough, we can subdivide the domain $Q = [0, 1] \cross [0,1]$ into $N^2$
	smaller squares of sidelength $\frac{1}{N}$ such that, for each small square $Q'$, the image
	$\Gamma(Q')$ is included in some ball in $U$.

	Let $\eta_0$ be the curves that travels from $(0,0)$ to $(1,1)$ along the bottom and
	the right side of $Q$ and $\eta_1$ a curve with the same endpoints which travels along the
	left and top side instead.
	Now consider the integral $\int_{\Gamma \circ \eta_0} f(z) \dd z$: the right side (and the
	left side as well) contribute nothing to the integral since they are just moving from a curve to
	another.

	Let $Q'$ be the bottom-right square of the given subdivision and $\eta_1$ be the slightly
	modified curve which rather travels on the other two sides of $Q'$ (left and top instead of bottom
	right) and agrees with $\eta_0$ everywhere else.
	Now, since $Q'$ is included in a ball where a local primitive exists, we have
	\begin{equation}
		\int_{\Gamma \circ \eta_0} f(z) \dd z = \int_{\Gamma \circ \eta_1} f(z) \dd z
	\end{equation}

	Now consider the small square $Q''$ next to $Q'$ and perform the same modification to $\eta_1$
	obtaining the curve $\eta_2$. After repeating the steps $N^2$ times we obtain that
	\begin{equation}
		\int_{\gamma_0} f(z) \dd z = \int_{\Gamma \circ \eta_0} f(z) \dd z = \dots =
		\int_{\Gamma \circ \eta_{N^2}} f(z) \dd z = \int_{\gamma_1} f(z) \dd z
	\end{equation}
	as desired.
\end{proof}

\begin{theorem}{Cauchy integral theorem}{cauchy-integral}
	If $f : U \to \C$ is homotopic and $\gamma$ is a continuous loop which can be continuously
	deformed into a point (among loops in $U$) then
	\begin{equation}
		\int_\gamma f(z) \dd z = 0
	\end{equation}
\end{theorem}
\begin{proof}
	If $\gamma$ is homotopic to a constant curve $\gamma_1$ then, by \cref{thm:invariance-homotopies},
	\begin{equation}
		\int_\gamma f(z) \dd z = \int_{\gamma_1} f(z) \dd z =
		\int_s^t f(\gamma_1(t)) \cdot \gamma_1'(t) \dd z = 0
	\end{equation}
	since $\gamma_1' = 0$.
\end{proof}

\begin{theorem}{Cauchy integral formula}{cauchy-integral-formula}
	If $\overline B_r(z_0) \subseteq U$ for $f$ homotopic we have
	\begin{equation}
		f(z_0) = \frac{1}{2 \pi i} \int_{\partial B_r(z_0)} \frac{f(z)}{z - z_0} \dd z
	\end{equation}
	where $\partial B_r(z_0)$ is travelled counterclockwise.
\end{theorem}

Note that we can replace $\partial B_r(z_0)$ with any loop in $\C \setminus \{z_0\}$
homotopic to it.

\begin{proof}
	Not in the exam; see lecture 4.
\end{proof}

\section{Differential geometry}

\subsection{Inverse function theorem}

\begin{definition}{Diffeomorphism}{diffeomorphism}
	Let $U, V \subseteq \R^n$ both open. A function $\Phi : U \to V$ is a diffeomorphism if it is
	bijective, with $\Phi$ and $\Phi^{-1}$ both of class $C^1$.

	Moreover, we say that $\Phi$ is a diffeomorphism \emph{with its image} if $V = \Phi(U)$.
\end{definition}

\begin{theorem}{Inverse function theorem}{inverse-func}
	Let $f: U \to \R^n$ of class $C^1$ with $U \subseteq \R^n$ open.
	If the differential $Df(x_0)$ is invertible at a given point $x_0 \in U$, then there exists a
	smaller open set $U' \subseteq U$ such that $x_0 \in U'$, $f(U')$ is open and $f \eval_{U'}$ is a
	bijection from $U'$ to $f(U')$ with a $C^1$ inverse.

	In other words, $f\eval_{U'}$ is a diffeomorphism with its image.
\end{theorem}

This theorem essentially says that the Taylor expansion $T_1(x) = f(x_0) + (Df(x_0))(x-x_0)$ is
invertible if $f$ is also invertible near $x_0$.

\begin{proof}
	TODO: thm 9.1
\end{proof}

\begin{theorem}{Implicit function theorem}{implicit-func}
	Let $P \subset \R^k$ and $S, V \subseteq \R^n$, all open, and a function $f: P \cross S \to V$ of
	class $C^1$.
	If $D_s f(p_0, s_0)$ is invertible for some $(p_0, s_0) \in P \cross S$ then, letting
	$v_0 = f(p_0, s_0)$, there exists some smaller sets $P' \subseteq P$, $S'\subseteq S$, and
	$V' \subseteq V$ containing $p_0, s_0, v_0$ respectively such that, for $p \in P'$ and $v \in V'$
	the equation $f(p, s) = v$ has an unique solution $s \in S'$.
	Furthermore, the assignment $(p, v) \to s$ giving the solution is a $C^1$ function
	$P \cross V \to S$.
\end{theorem}

Basically this theorem gives us a way of finding a solution to a non-linear equation $f(p, s) = v$
for $s$ given a value $v$ and a parameter $p$.
Note that if we fix the parameter $p = p_0$ we are back to the same situation as the inverse
function theorem.

This is why we impose the condition that $D_s f$ (the differential of $f$ limited to the partial
derivatives in $s_1, \dots s_n$) is invertible at $(p_0, s_0)$.
Recall that the differential is a matrix, in this case $n \cross (k + n)$, and can be written as
\begin{equation}
	Df(p_0, s_0) = (D_p f(p_0, s_0) \mid D_s f(p_0, s_0))
\end{equation}

\begin{proof}
	TODO: thm 9.3
\end{proof}

\subsection{Definition of manifold}

Intuitively a $k$-dimensional manifold is a subset of $\R^n$, with $k \in \{1, \dots, n\}$, which
resembles an affine space of dimension $k$ close to any point in it. In other words, if we zoom in
to a point in the manifold we have something that looks like a straight line.

\begin{definition}{First definition of manifold}{manifold-1}
	A set $M \subseteq \R^n$ is a $k$-dimensional manifold if, for any $p \in M$, there exists an open
	set $U \subseteq \R^n$, such that $p \in U$, and a function $\Phi : U \to \R^n$ which is a diffeomorphism with
	its image, such that
	\begin{equation}
		\Phi(M \cap U) = [\R^k \cross \{0\}] \cap \Phi(U)
	\end{equation}
\end{definition}

This definition tells us that, within a set $U$, we can deform the portion of $M$ contained in $U$
top obtain a $k$-dimensional plane (or, more precisely, the portion of this plane included in
$\Phi(U)$).
The notation $\R^k \cross \{0\}$ indicates a $k$-dimensional subspace of $\R^n$: for example, if
$n = 3$ and $k = 2$ we would obtain the $xy$ plane \emph{in} $\R^3$, i.e. the set of points
$(x, y, 0) \in \R^3$.

\begin{definition}{Second definition of manifold}{manifold-2}
	A set $M \subseteq \R^n$ is a $k$-dimensional manifold if, for any $p \in M$, there exists an open
	set $U \subseteq \R^n$, such that $p \in U$, and a function $h: U \to \R^{n-k}$ such that $Dh(p)$
	is surjective (or, equivalently, has full rank) and
	\begin{equation}
		M \cap U = \{ x \in U : h(x) = 0 \}
	\end{equation}
\end{definition}

This definition is kind of complementary to the previous one: it says that $M$ is locally the zero
of a function with values in $\R^{n-k}$, which imposes $n-k$ constraints.

\begin{definition}{Third definition of manifold}{manifold-3}
	A set $M \subseteq \R^n$ is a $k$-dimensional manifold if, for any $p \in M$, there exists an open
	set $U \subseteq \R^n$, such that $p \in U$, an open set $V \subseteq \R^k$, and a
	\emph{parametrization} $\psi: V \to U$, that is $\psi$ of class $C^1$ with the following
	properties:
	\begin{itemize}
		\item $D \psi (x) $ is injective (or, equivalently, has full rank) for all $x \in V$;
		\item $\psi$ is a homeorphism with its image, that is $\psi$ as a map from $V \to \psi(V)$ is
		      bijective and has continuous inverse;
		\item $M \cap U = \psi(V)$.
	\end{itemize}
\end{definition}

Here we are told that around any point $p \in M$ we can write $M$ as the image of a parametrization
$\psi$. Note that it is enough to check the first condition at $\psi^{-1}(p)$ because $D\psi$ is
continuous.

\begin{definition}{Fourth definition of manifold}{manifold-4}
	A set $M \subseteq \R^n$ is a $k$-dimensional manifold if, for any $p \in M$, up to a permutation
	of the coordinates, there exists an open set $U \subseteq \R^n$ of the form $U = V \cross W$, with
	$V \subseteq \R^k$ and $W \subseteq \R^{n - k}$ both open, and a function $\tilde \psi: V \to W$
	of class $C^1$ such that $M \cap U$ is the graph of $\tilde \psi$, i.e.
	\begin{equation}
		M \cap U = \{ (x, \tilde \psi(x)) \mid x \in V\}
	\end{equation}
\end{definition}


\begin{theorem}{Equivalence of the definitions of manifold}{equivalence-def-manifold}
	The four definitions of manifold (\cref{def:manifold-1}, \cref{def:manifold-2},
	\cref{def:manifold-3}, and \cref{def:manifold-4}) are equivalent.
\end{theorem}
\begin{proof}
	TODO: thm 9.9
\end{proof}

\subsection{Spaces on manifolds}
\subsubsection{Tangent space}

\begin{definition}{Tangent space}{tangent-space}
	Let $M$ be a manifold and $p \in M$. The tangent space to $M$ at point $p$ is defined as
	\begin{equation}
		T_p M = \{ \gamma'(0) \mid \gamma: [0, \varepsilon] \to M \text{ of class } C^1 \text{ with }
		\gamma(0) = p \text{ and } \varepsilon > 0 \}
	\end{equation}
\end{definition}
In other words we consider all the possible initial speeds of the curves starting at $p$ and
travelling along $M$.

\begin{proposition}{Tangent space is linear}{tangent-space-linear}
	The tangent space $T_p M$ of a $k$-dimensional manifold $M$ at $p$ is a $k$-differential linear
	subspace of $\R^n$ for any $p \in M$.
\end{proposition}

\begin{proof}
	TODO: prop 10.2
\end{proof}

\subsubsection{Tangent cone}

\begin{definition}{Tangent cone}{tangent-cone}
	Given a set $S \subseteq \R^n$ and $p \in S$, we define the tangent cone of $S$ at $p$ as
	\begin{equation}
		T_p S = \left\{ \lambda v \mid \lambda \geq 0,
		v = \lim_{i \to \infty} \frac{p^{(i)} - p}{\abs{p^{(i)} - p}}\right\}
	\end{equation}
	where we consider any sequence $p^{(i)} \in S \setminus \{p\}$ such that $p^{(i)} \to p$ and
	$\frac{p^{(i)} - p}{\abs{p^{(i)} - p}}$ also converges.

	If $p$ is isolated in $S$ we let $T_p S = \varnothing$.
\end{definition}

In other words, we consider all possible limit directions of approaching $p$ within $S$ and we
consider all non-negative multiples of them.

\begin{proposition}{Tangent cone are necessary for manifold}{cone-necessary-manifold}
	If $S$ is a $k$-dimensional manifold, then $T_p S$ is a $k$-dimensional vector space.
\end{proposition}

Note that this condition is not sufficient, counterexample in remark 10.6.
Moreover, if $S$ is convex, the tangent cone ends up being equivalent to the closure of the one we
defined in advanced programming.

\begin{proof}
	TODO: prop 10.5
\end{proof}

\subsection{Smooth maps between manifolds}

For us smooth means $C^1$ although some time it may be more strict.
We want to define what it means for a function $f: M \to N$ to be smooth, where $M \subseteq \R^m$
and $N \subseteq \R^n$ are both manifolds.

\begin{definition}{Smooth maps to a manifold}{}
	Given a set $U \subseteq \R^m$ and a function $f: U \to N$ we say that $f$ is smooth if
	$f: U \to \R^n$ is of class $C^1$ in the usual way, that is, differentiable with continuous
	differential.
\end{definition}

\begin{definition}{Smooth maps from a manifold}{smooth-map-from-manifold}
	Let $f: M \to \R^n$. $f$ is smooth if for all parametrizations $\psi: V \to M$
	(as in \cref{def:manifold-3}) defined on an open set $V \subseteq \R^k$ so that the composition
	\begin{equation}
		f \circ \psi: V \to \R^k
	\end{equation}
	is of class $C^1$.
\end{definition}

We would need to check this for infinitely many parametrizations, however, luckily, it is usually
enough to check finitely many of them.

\begin{proposition}{}{}
	Let $\psi^{(i)}: V^{(i)} \to M$ be a family of parametrizations for $i \in I$ so that
	$M = \bigcup_{i \in I} \psi^{(i)}(V^{(i)})$.
	Then a map $f: M \to \R^n$ is smooth if and only if each composition $f \circ \psi^{(i)}$ is
	$C^1$.
\end{proposition}

\begin{proof}
	skip.
\end{proof}

\begin{proposition}{}{}
	A function $f: M \to \R^n$ is of class $C^1$ if and only if, for any $p \in M$, there exists an
	open set $U$ such that $p \in U$ and $\tilde f: U \to \R^n$ of class $C^1$ such that
	\begin{equation}
		f |_{M \cap U} = \tilde f |_{M \cap U}
	\end{equation}
\end{proposition}

\begin{proof}
	TODO: prop 12.6
\end{proof}

\begin{definition}{Smooth map between manifolds}{}
	A function $f: M \to N$ is smooth if it is smooth according to \cref{def:smooth-map-from-manifold}
	when viewed as a map $f: M \to \R^n$.
\end{definition}

\begin{definition}{Diffeomorphism between manifolds}{}
	A function $f: M \to N$ is a diffeomorphism it is bijective and $f$ and $f^{-1}$ are both smooth.
\end{definition}

\subsubsection{Differential of smooth functions between manifolds}

\begin{definition}{Differential of a smooth function between manifolds}{differential-smooth}
	Given a $C^1$ function $f: M \to N$ between two manifolds $M, N$, for any point $p \in M$ we
	define the differential of $f$ at $p$ as the \emph{linear} map
	\begin{equation}
		Df(p): T_p M \to T_{f(p)} N
	\end{equation}
	defined as
	\begin{equation}
		Df(p)[\gamma'(0)] = (f \circ \gamma)' (0)
	\end{equation}
	for any $\gamma: [0, \varepsilon] \to M$ of class $C^1$ with $\gamma(0) = p$.
\end{definition}

\begin{proposition}{Differential is well defined}{}
	The differential is well-defined (i.e. for two different $\gamma_1, \gamma_2$ we would obtain the
	same result) and linear.
	Moreover, given any $p \in M$ and a local $C^1$ extension $\tilde f: U \to \R^n$ near $p$, we have
	\begin{equation}
		Df(p)[v] = D\tilde f (p)[v]
	\end{equation}
	for any $v \in T_p M$.
\end{proposition}
\begin{proof}
	TODO: prop 13.3
\end{proof}




\end{document}
