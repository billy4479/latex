\documentclass[14pt]{extarticle}
\title{Linear Algebra Notes}
\author{Giacomo Ellero}

\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{commath}
\usepackage{dirtytalk}
\usepackage{parskip}
\usepackage{mathrsfs}
\usepackage[many]{tcolorbox}
\usepackage{xparse}
\usepackage[a4paper,margin=1.5cm]{geometry}

\newcommand{\C}{\mathbb{C}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\citeladr}[1]{
    \begin{quotation}
        This section references \say{Linear Algebra Done Right}, #1
    \end{quotation}
}
\newcommand{\innerprod}[1]{
    \langle #1 \rangle
}
\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}

\newenvironment{absolutelynopagebreak}
  {\par\nobreak\vfil\penalty0\vfilneg
   \vtop\bgroup}
  {\par\xdef\tpd{\the\prevdepth}\egroup
   \prevdepth=\tpd}

\newtcolorbox{statementbox}[1]{colback=green!5!white,colframe=green!40!black,title={#1},fonttitle=\bfseries}

\NewDocumentEnvironment{statement}{ O{} O{Theorem} m}{
\begin{absolutelynopagebreak}
\subsubsection{#3}
{#1}
\begin{statementbox}{#2}
}
{
\end{statementbox}
\end{absolutelynopagebreak}
}


\begin{document}

\maketitle
\tableofcontents
\clearpage

\section{Inner product spaces}

\citeladr{Chapter 6}

\subsection{Inner product and norms}

\citeladr{Chapter 6.A}

\begin{statement}[][Definition]{Definition of complex conjugate}

    Let $z \in \C$, then

    $$
        \overline z = \overline{a + bi} = a - bi
    $$

\end{statement}

\begin{statement}[][Definition]{Definition of complex absolute value}

    Let $z \in \C$, then

    $$
        |z| = \sqrt{a^2 + b^2}
    $$

    and

    $$
        |z|^2 = z \overline z
    $$
\end{statement}

\begin{statement}[\citeladr{6.8}][Definition]{Definition of norm}

    Let $v \in V$, then

    $$
        \norm v = \sqrt{\langle v, v \rangle}
    $$

\end{statement}

\begin{statement}[\citeladr{6.11}][Definition]{Definition of orthogonal}

    Two vectors $u, v$ are orthogonal if

    $$
        \langle v, u \rangle = 0
    $$

    This is just a fancy way to say they are perpendicular since, for example, in $\R^2$, $\langle v, u \rangle = \norm v \norm u \cos \theta$.

\end{statement}

\begin{statement}[\citeladr{6.13}]{Pythagorean theorem}

    Let $v, u \in V$ be orthogonal, then

    $$
        \norm{u+v}^2 = \norm u^2 + \norm v^2
    $$

\end{statement}

\begin{statement}[\citeladr{6.14}]{Orthogonal Decomposition}

    Let $v, u \in V$ and $w = u - cv$ orthogonal to $v$.

    We want to find $c \in \F$ and such that

    $$
        u = cv + w
    $$

    To solve this problem we set

    $$
        c = \frac{\innerprod{u, v}}{\norm v^2},
        \quad
        w = u - \frac{\innerprod{u, v}}{\norm v^2} v
    $$

    In this way we have that $u = cv + w$ and $\langle v, w \rangle = 0$

\end{statement}

\begin{statement}[\citeladr{6.15}]{Cauchy-Schwarz Inequality}

    Let $u, v \in V$. Then

    $$
        |\innerprod{u, v} \le \norm u \norm v
    $$
\end{statement}

\begin{proof}
    Consider the orthogonal decomposition $u = cv + w$.
    Since $cv$ is orthogonal to $w$, by the Pythagorean Theorem we have that

    \begin{align*}
        \norm u ^2 & = \norm {c v}^2 + \norm w^2                                             \\
                   & = \norm {\frac{\innerprod{u, v}}{\norm v^2} v}^2 + \norm w^2            \\
                   & = \left(\frac{\innerprod{u, v}}{\norm v^2} \norm v\right)^2 + \norm w^2 \\
                   & = \frac{|\innerprod{u, v} |^2}{\norm v^2} + \norm w^2                   \\
                   & \ge \frac{|\innerprod{u, v} |^2}{\norm v^2}                             \\
    \end{align*}

    Now we take square roots on both sides and rearrange the terms to get our result.

\end{proof}

\begin{statement}[\citeladr{6.18}]{Triangle Inequality}

    Let $u, v \in V$. Then

    $$
        \norm{u+v} \le \norm u + \norm v
    $$
\end{statement}

\begin{proof}
    \begin{align*}
        \norm{u+v}^2 & = \innerprod{u+v, u+v}                                                                 \\
                     & = \innerprod{u, u} + \innerprod{v,v} + \innerprod{u, v} + \innerprod{v, u}             \\
                     & = \innerprod{u, u} + \innerprod{v,v} + \innerprod{u, v} + \overline {\innerprod{u, v}} \\
                     & = \norm u^2 + \norm v^2 + 2 \Re \innerprod{u, v}                                       \\
                     & \le \norm u^2 + \norm v^2 + 2|\innerprod{u, v}|                                        \\
                     & \le \norm u^2 + \norm v^2 + 2 \norm u \norm v                                          \\
                     & = (\norm u + \norm v)^2
    \end{align*}
\end{proof}

\begin{statement}[\citeladr{6.22}]{Parallelogram Equality}

    Let $u, v \in V$. Then

    $$
        \norm {u+v}^2 + \norm{u-v}^2 = 2 (\norm u^2 + \norm v^2)
    $$
\end{statement}
This is quite easy to prove just with the definition of norm and inner product.

\clearpage

\subsection{Orthonormal Bases}

\citeladr{Chapter 6.B}


\begin{statement}[\citeladr{6.23}]{Definition of Orthonormal List}

    A list of vectors is orthonormal if each vector has norm 1 and
    is orthogonal to the other vectors in the list.

    This means that in an orthonormal list $e_1, \dots, e_n$ of vectors in $V$

    $$
        \innerprod{e_i, e_j} = \begin{cases*}
            1  \text{ if } j = k, \\
            0  \text{ if } j \ne k
        \end{cases*}
    $$
\end{statement}
From now on when we usually denote an orthonormal lists of vectors with $e_i$.

\begin{statement}[\citeladr{6.25}]{Norm of an orthonormal linear combination}

    Let $e_1, \dots, e_n$ orthonormal. Then

    $$
        \norm{a_1 e_1 + \dots + a_n e_n} = |a_1|^2 + \dots + |a_n|^2
    $$

    for all $a_1, \dots, a_n \in \F$.
\end{statement}
\begin{proof}
    This is just the repeated application of the Pythagorean Theorem.
\end{proof}


\begin{statement}[\citeladr{6.26, 6.27 and 6.28}]{Definition of Orthonormal Basis}
    As a corollary of the previous theorem we have that \textbf{every orthonormal list of vectors is linearly independent}.
    This is quite obvious from the previous theorem.

    It follows that if we have an orthonormal list of the right length we can form a basis.
    Such basis will be referred as an \textbf{orthonormal basis}.
\end{statement}

\begin{statement}[\citeladr{6.30}]{Writing a Vector as a L.C. of Orthonormal Basis}

    Let $e_1, \dots, e_n$ be an orthonormal basis of $V$ and $v \in V$.
    Then

    $$
        v = \innerprod{v, e_1}e_1 + \dots + \innerprod{v, e_n}e_n
    $$

    and

    $$
        \norm v^2 = |\innerprod{v, e_1}| + \dots + |\innerprod{v, e_n}|
    $$

\end{statement}

\begin{statement}[\citeladr{6.31}]{Gram-Schmidt Procedure}

    This is a procedure for finding orthonormal basis of a given vector space.

    Let $v_1, \dots, v_n$ be a basis of $V$.
    Define by induction the list $e_1, \dots, e_n$ such that for $i = 1$ we have that

    \begin{align*}
        v_1' & = v_1                   \\
        e_1  & = \frac{v_1}{\norm v_1} \\
    \end{align*}

    $\forall i \ge 2$ we define

    \begin{align*}
        v_i' & = v_i - \innerprod{v_i, e_1}e_1 - \dots - \innerprod{v_i, e_{j-1}}e_{j-1} \\
        e_i  & = \frac{v_i'}{\norm {v_i'}}                                               \\
    \end{align*}

\end{statement}

\begin{statement}[\citeladr{6.42}]{Riesz Representation Theorem}
    Let $V$ be finite-dimensional and $\varphi: V \to \F$.
    Then there exists an unique $u \in V$ such that

    $$
        \forall v \in V, \quad \varphi(v) = \innerprod{v, u}
    $$

    This gives an isomorphism between $V' = \mathscr L(V, \F)$ and $V$.
\end{statement}

\clearpage

\subsection{Orthogonal Complements}

\citeladr{Chapter 6.B}

\begin{statement}[\citeladr{6.45}]{Definition of Orthogonal Complement}
    Let $U \subset V$ (not necessarily a subspace).
    Then we denote as $U^\perp$ the \textbf{orthogonal complement} of $U$
    the set of all vectors in $V$ orthogonal to every vector in $U$.

    $$
        U^\perp = \{ v \in V \enspace | \enspace \forall u \in U, \innerprod{v, u} = 0 \}
    $$

\end{statement}

\begin{statement}[\citeladr{6.46, 6.47, and 6.48}]{Proprieties of the Orthogonal Complement}

    Applying the Riesz theorem we get an isomorphism between $U^\perp$ and $U^\circ$.

    \tcbline

    The following proprieties hold:

    \begin{enumerate}
        \item $U^\perp$ is a linear subspace of $V$
        \item $\{\underline 0\}^\perp = V$
        \item $V^\perp = \{\underline 0\}$
        \item $U \cap U^\perp$ is either $\{\underline 0\}$ or $\varnothing$
        \item If $U \subseteq W$, then $W^\perp \subseteq U^\perp$
    \end{enumerate}

    \tcbline

    Also it holds that

    $$
        V = U \oplus U^\perp
    $$

    \tcbline

    Moreover, if $V$ is finite-dimensional we get that

    $$
        \dim U^\perp = \dim V + \dim U
    $$



\end{statement}

\clearpage

\section{Operators on Inner Product Spaces}

\citeladr{Chapter 7}

\subsection{Self-Adjoint and Normal Operators}

\citeladr{Chapter 7.A}

\begin{statement}[\citeladr{7.11}]{Definition of Self-Adjoint Mapping}
    A linear mapping $T \in \mathscr L(V)$ is self-adjoint if and only if

    $$
        \forall v, w \in V, \quad \innerprod{Tv, w} = \innerprod{v, Tw}
    $$
\end{statement}

\begin{statement}[\citeladr{7.10 (chopped)}]{Transpose and Conjugate of Self-Adjoint Mapping}

    Let $V$ be finite-dimensional, $T$ be a self-adjoint mapping on $V$,
    and $\mathscr B = (e_1, \dots, e_n)$ be an orthogonal basis of $V$.

    Then the matrix $A$ of $T$ relative to $\mathscr B$ has the following propriety

    $$
        A' = \overline A
    $$

    (The transpose of $A$ is its conjugate.)

\end{statement}

\begin{statement}[\begin{quote}
            This section references the slides of week 11 and is not contained in this chapter of "Linear Algebra Done Right".
        \end{quote}]{Transpose of the Product of Matrices}

    Let $A \in \mathscr M_{m,n}(F)$ and $B \in \mathscr M_{n, p}(F)$ such that $AB$ is defined. Then

    $$
        (AB)' = B'A'
    $$

\end{statement}

This is a quite general result that will be useful for other proofs even though it's not strictly part of this topic.

\clearpage

\subsection{The Spectral Theorem}

\citeladr{Chapter 7.B}

\begin{statement}{Eigenvalues of Self-Adjoint Mapping are Real}
    Let $T$ be a self-adjoint mapping on $V$.
    Then all the eigenvalues of $T$ are real.

    In other words if a matrix $A$ is such that $A' = \overline A$,
    then $P_A$ (characteristic polynomial) has all roots in $\R$.
\end{statement}

\begin{statement}[\citeladr{7.24 and 7.29}]{The Spectral Theorem}

    Let $V$ be finite-dimensional and $T$ be a self-adjoint mapping on $V$.
    Then there exists an orthonormal basis of $V$ consisting of eigenvectors of $T$.

    Moreover if $\F = \R$ this is an equivalence (if and only if).

\end{statement}
\begin{proof}
    We proceed by induction on the dimension of $V$.
    Let $n = \dim V$.

    First, if $n = 1$ there is nothing more to prove
    since we saw already that $T$ has at least one eigenvalue.

    If $n \ge 2$ let $\lambda$ be an eigenvalue of $T$ and $u$ its eigenvalue.
    We can find another eigenvector of $T$ $u_n = \frac{u}{\norm u}$.
    Let $U = [u_n]$ (the span of $u_n$) and $U^\perp$ which will have $\dim U^\perp = n-1$.

    We now want to prove that any $Tv \in U^\perp$.
    To do so we have to show that any $Tv$ is orthogonal to $u_n$.
    We proceed as follows:

    $$
        \innerprod{Tv, u_n} \stackrel{\text{self-adjoint}}{=}
        \innerprod{v, Tu_n} \stackrel{\text{eigenvector}}{=}
        \innerprod{v, \lambda u_n} \stackrel{\text{semi-linearity}}{=}
        \overline \lambda \innerprod{v, u_n} \stackrel{\text{orthognality of } U^\perp}{=}
        0
    $$

    (Note that $\lambda \in \R$, so $\overline \lambda = \lambda$.)

    Then we can restrict $T$ such that $\tilde T: U^\perp \to U^\perp$.
    $\tilde T$ is a self-adjoint mapping of $U^\perp$,
    hence we can repeat the procedure and get an orthonormal basis of $U^\perp$
    made of eigenvectors of $\tilde T$ that looks like $u_1, \dots, u_{n-1}$.
    To this list we append $u_n$ so that the resulting list $u_1, \dots, u_{n-1}, u_n$
    is an orthonormal basis of $V$ consisting of eigenvectors of $T$.

\end{proof}

\end{document}
